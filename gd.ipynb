{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f14f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5f7ed",
   "metadata": {},
   "source": [
    "Queremos minimizar la función de pérdida:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7422a5",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_{i=1}^{N} \\left( f^*(\\mathbf{i}_i) - d_i \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d52f2",
   "metadata": {},
   "source": [
    "Es decir, queremos minimizar la diferencia entre los diagnósticos que predice el modelo y los reales. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044668eb",
   "metadata": {},
   "source": [
    "Buscamos la mejor solución dentro de las funciones $f : \\mathbb{R}^K \\to (0, 1)$\n",
    " que tengan la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43675cbf",
   "metadata": {},
   "source": [
    "$$\n",
    "f_{\\mathbf{w}, b}(\\mathbf{i}) = \\frac{\\tanh(\\mathbf{w} \\cdot \\mathbf{i} + b) + 1}{2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539bda14",
   "metadata": {},
   "source": [
    "donde $w$ es un vector de $\\mathbb{R}^K$ , $b$ un escalar, y $tanh$ la tangente hiperbólica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8a456",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee9a5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_convert(dir, new_size):\n",
    "    \n",
    "    imagenes = []\n",
    "\n",
    "    for filename in os.listdir(dir):\n",
    "\n",
    "        file_path = os.path.join(dir, filename)\n",
    "        # print(f\"Procesando imagen {file_path}\")\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "\n",
    "            # Sin este if no funciona en mi windows, probar comentarlo en Mac a ver que pasa\n",
    "            if not filename.lower().endswith('.png'):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    img = img.resize(new_size) \n",
    "                    img = img.convert('L') # Convertir a escala de grises\n",
    "                    img_array = np.array(img)/255.0 # Convertir a array y normalizar\n",
    "                    img_vector = img_array.reshape((new_size[0]**2)) \n",
    "                    imagenes.append(img_vector)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando la imagen {file_path}: {e}\")\n",
    "\n",
    "    return np.array(imagenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21cc78a",
   "metadata": {},
   "source": [
    "Convertimos las imágenes a arreglos de pixeles y separamos en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a06e2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino tamaño de compresion\n",
    "original = (256, 256)\n",
    "mediano =  (128, 128)\n",
    "chico = (64, 64)\n",
    "muy_chico = (32, 32)\n",
    "\n",
    "new_size = chico  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a5737d",
   "metadata": {},
   "source": [
    "En el dataset provisto tenemos 1617 dibujos de pacientes sanos y 1629 dibujos de pacientes con parkinson.\n",
    "\n",
    "Cómo armamos el conjunto de entrenamiento?\n",
    "* Tiene que tener cantidades parecidas de pacientes con y sin parkinson.\n",
    "* Aproximadamente el 70% del total de observaciones deberían ir al conjunto de entrenamiento\n",
    "\n",
    "Podemos hacerlo asi: \\\n",
    "train \\\n",
    "sanos: 1132 \\\n",
    "enfermos: 1140 \n",
    "\n",
    "test \\\n",
    "sanos: 485 \\\n",
    "enfermos: 489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53e32045",
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_healthy_train = 1132\n",
    "cant_park_train = 1140\n",
    "\n",
    "cant_healthy_test = 485\n",
    "cant_park_test = 489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26aa8b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Convierto todas las imágenes a arreglos de pixeles según el tamaño elegido\n",
    "\n",
    "# Healthy\n",
    "src_dir = 'DatasetTP/Healthy'\n",
    "i_healthy = image_convert(src_dir, new_size) \n",
    "d_healthy = np.ones((i_healthy.shape[0], 1)) * 0 # Vector de diagnósticos para la gente sana (0)\n",
    "\n",
    "# Parkinson\n",
    "src_dir = 'DatasetTP/Parkinson'  \n",
    "i_park = image_convert(src_dir, new_size) \n",
    "d_park = np.ones((i_park.shape[0], 1)) # Vector de diagnósticos para la gente con Parkinson (1)\n",
    "\n",
    "# Separo en train y test\n",
    "i_healthy_train = i_healthy[:cant_healthy_train]\n",
    "d_healthy_train = d_healthy[:cant_healthy_train]\n",
    "\n",
    "i_healthy_test = i_healthy[cant_healthy_train:cant_healthy_train + cant_healthy_test]\n",
    "d_healthy_test = d_healthy[cant_healthy_train:cant_healthy_train + cant_healthy_test]\n",
    "\n",
    "i_park_train = i_park[:cant_park_train]\n",
    "d_park_train = d_park[:cant_park_train]\n",
    "\n",
    "i_park_test = i_park[cant_park_train:cant_park_train + cant_park_test]\n",
    "d_park_test = d_park[cant_park_train:cant_park_train + cant_park_test]\n",
    "\n",
    "# Combino sanos y enfermos en train y test\n",
    "i_train = np.vstack((i_healthy_train, i_park_train)) # Imágenes de entrenamiento\n",
    "d_train = np.vstack((d_healthy_train, d_park_train)) # Diagnósticos de entrenamiento\n",
    "\n",
    "i_test = np.vstack((i_healthy_test, i_park_test)) # Imágenes de test\n",
    "d_test = np.vstack((d_healthy_test, d_park_test)) # Diagnósticos de test\n",
    "\n",
    "# Mezclo los datos de entrenamiento y test\n",
    "np.random.seed(42)  \n",
    "np.random.shuffle(i_train)\n",
    "np.random.shuffle(d_train)\n",
    "np.random.shuffle(i_test)\n",
    "np.random.shuffle(d_test)\n",
    "\n",
    "# Chequeamos que la intersección entre train y test sea nula (Importante)\n",
    "print(len(set(map(tuple, i_train)).intersection(map(tuple, i_test))) == 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "td6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
